技术：机器学习和一览无余的隐私

5 读书报告：计算机技术对人类社会产生了巨大影响，改变了人类的生产和生活方式，请从工程伦理学的角度，对某一种具体的计算机技术已经或可能引发的伦理问题进行深入论述，阐明其背景、问题、现状、发展趋势、相应对策，要充分加入本人思考，有理有据，引证翔实，图文并茂，规范引用，列明参考文献，要求每人独立完成，不少于3000字，严禁抄袭，具体格式参见宁波大学学报理工版(http://journallgnbueducn/)论文格式，14周末以前上交。

#+begin_quote This is my world
不那么智能的人工智能和隐私的被“狂欢”，
摘要：比起不懂技术的人疯狂鼓吹的人工智能相关的伦理问题，弱人工智能被喂入的大量授权/来源都很有问题的大数据才会带来更大的伦理问题。

近年来，大数据/人工智能已经成为了最热门的词汇，它们间的关联也越来越为大众所致，机器学习等词汇变得逐渐广为周知，似乎所有行业不说“智能”就显得out了。
也能见到很多常见的科学狂想小说里，很多人在人工智能的自由意志问题、主体性问题、新型人机关系问题，不夸张地说，我认为写这些多半都只是个噱头或者是纯粹的“狂想”：
我们可以从它的来源进行探讨
一般认为人工智能的术语起源于1956年美国达特茅斯会议John McCarthy等人提出的“使用机器模拟人类智能”概念,后经概率统计模型、深度学习技术使人工智能在语音、图像、数据挖掘、自然语言处理等多个领域取得突破进展;
你看，人工智能是一个概率统计和“深度学习”综合起来得出”结果”的技术.[[https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&filename=ZDJY201812012&v=MjEzNzJyWTlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3dWZZZVpxRkN2blViN0JQeW5CZDdHNEg5bk4=&uid=WEEvREcwSlJHSldSdmVqMDh6a1dpRHpuSEhpQXJHVUxXUjZ1eXFlS012VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!][[1]]，现在的人们更多的是在尝试用大数据喂养自己的算法，离提起所谓的自由意志/主体性/新型人际关系差:距还有非常远的位置，大家只是在教育人工智能，离人工智能能教育我们还有非常遥远的距离。即便我反对他们的定义，在这里我也只能给出非常简易的定义，因为定义这个概念本身就很困难，一个原因是人工智能包含的内容在不断变化，而这种变化很难以准确的语言进行描述。正如哲学视角下事物变化的一般规律，人工智能的发展也同样是持续前进和不断更新的。著名哲学家、牛津大学人类未来研究所创始主任尼克·博斯特罗姆教授认为，“很多前沿的人工智能已经渗透到一般的应用中，通常不被称为人工智能，因为一旦某样东西变得足够有用、足够普遍，它就不再被称为人工智能了。”以上论述说明人工智能目前仍处于不断发展的阶段，难以用统一和完备的视角去解读这一复杂多变的综合体。这就是人工智能的矛盾之处：
人人爱他，但人人也搞不清楚自己爱的是什么。
我们本次会着力于更多的探讨弱人工智能和它们的伦理问题，而不是讨论更加迷幻的强人工智能.先给定义：
弱人工智能ANI是指人工系统，通常指专注于某些领域、实现专用或特定技能的智能，如人脸识别、机器翻译等，虽然它们逐渐具备了所谓的自我学习能力，但只会在各自的领域学习，而不会像人类一样具有好奇心，也不会自主地探索新的技术和方法[[https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html][[2]],也是为众人所吹捧的“人工智能“的主要种类。

人工智能发展到现在已经经历了三个阶段,
1946年世界上第一台现代电子计算机ENIAC的诞生为人工智能奠定了计算基础，1956年Jhon McCarthy教授等人在达特茅斯会议上提出人工智能的概念，一般认为这象征着人工智能概念的诞生。在随后的十几年里，人工智能初步发展，计算机被广泛用于数学和自然语言领域，解决代数、几何和英语问题，计算机辅助教学（CAI）在教育领域逐渐兴起，但由于计算、逻辑理解的局限性，人工智能的发展逐渐走向低谷--即计算能力不是特别足够，无法解决问题——计算能力不是特别够，所以这种吃计算能力又没有太大效果的 "人工智能 "最好不要。
到了70年代初，以专家系统为代表的第一代人工智能开始出现，并被应用于医疗、农业气象、地质勘探、军事技术、商业咨询等诸多领域。专家系统可以概括为能够进行推理和判断的计算机程序和知识库，并模拟人类专家解决问题的过程。专家系统被广泛应用于各个行业，如医疗诊断专家系统、矿产勘探专家系统等。教育领域的专家系统以智能辅导系统ITS为代表，这一时期的智能辅导系统已经开始重视对学生个性和自主性的培养。其中许多专家系统在功能上已经达到甚至超过了人类专家在同一领域的水平，但由于专家系统的逻辑推理能力的限制，90年代的人工智能研究又逐渐进入了寒冬。
从21世纪初至今，计算机硬件能力不断增强，计算能力大幅提升，海量图像文本和语音数据等多模态数据不断涌现，这些发展为人工智能研究奠定了大数据的基础，所以从这个阶段开始，人工智能逐渐恢复并快速发展。2006年，深度学习概念的引入和大数据的兴起，推动了人工智能研究的爆发，有研究者也将2006年视为人工智能第三次发展的起始年。在这个阶段，各大公司和研究机构纷纷投入到深度学习研究中，谷歌Google Brain、微软语音识别、Facebook人脸识别等研究逐渐应用到人们生活的各个领域。特别是在教育领域，人工智能逐渐从关注教师和学生转向更广泛的全范围教育应用。伴随着大数据、深度学习等技术的快速发展，人工智能在这一阶段的各个领域发挥了重要的革命性作用。
然而，时至今日，经过近70年的发展，人工智能并没有突破发展的瓶颈。博斯特罗姆教授总结说："目前的技术离人类智能还很远，更不用说超级智能了"。人工智能与人类智能之间总是存在着普遍的差距，可以看出人类人工智能的发展还处于ANI初级阶段。虽然在某些领域，如举世瞩目的AlphaGo战胜李世石和柯洁事件表明，人工智能和深度学习在影响人类行为的感知和推理操作方面发挥了强大作用，但目前的人工智能还远远没有达到ANI发展的 "天花板"。展望未来，人工智能发展的历史进程可能在很短的时间内产生指数级的增长，这种趋势变化的 "奇点 "是现有技术难以窥见的。尽管无法预测人工智能的具体趋势，也很难在短时间内实现人工智能的真正教育价值，但教育研究者需要注意的是，人工智能的教育革命已经势不可挡。
上面虽然说得天花乱坠的,但现在的实践中,简单地说,人工智能其实就是摄入大数据给出"答案",大数据和大数据技术的本身就更是伦理的重中之重.
而大数据是怎么来的?是通过对使用主体的位置、身份、浏览足迹等隐私数据进行广泛收集、深度挖掘和分析并长期存储来的.
这里就是很显然的伦理问题,主要涉及数据隐私问题等，其对主体数据隐私的侵害具有隐私主体非自主性、初始数据来源易追溯、数据收集和分析过程不透明、隐私保护权责不明确、数据信息长期存储和可重复利用等特点。
各个政府都提出了一些保护方案,比如在大数据技术带来的数据隐私问题日益突出的背景下，欧盟制定了世界上第一部专门针对隐私和数据系统保护的法律，即《欧盟数据保护法》，并确立了 "数据遗忘权"；同样,美国加利福尼亚州政府制定了"橡皮擦"法案，以保护数据隐私的遗忘性。数据隐私保护的技术层面主要包括数据发布匿名保护技术、社交网络匿名保护技术、角色挖掘、风险适应性访问控制、数据溯源技术和数据水印技术等。
条条都是针对借"人工智能"为名大肆收集数据的恶徒,也规避了一些实际操作上数据的泄露.这时又引入了一个问题---技术发展总需要一些额外的牺牲,怎么样才能保证这些牺牲危害不大,但又能被使用到呢?
多数专家学者以分而治之的方式讨论大数据、人工智能等计算机新技术的伦理问题，具有很大的局限性。随着互联互通、数据共享的趋势逐渐明朗，人类所有的数据采集、存储和处理能力都趋于整合到同一个复杂的系统中，新的计算机技术伦理问题开始以系统性风险的形式出现，分而治之的方法似乎已经过时。在围绕数据的技术体系中，大数据技术为海量数据的采集、传输、存储和分析提供了基本的技术架构；人工智能技术专攻以深度学习为代表的数据分析技术；不同的计算机新技术共同为数据信息的采集、传输、存储、分析和呈现提供了基础或功能的技术支持。

人工智能的伦理问题可以被归结为包括数据边界和数据隐私在内的数据伦理问题.事实上，大数据技术已经将数据隐私问题作为其伦理问题的核心，并在技术和法律层面制定了一系列的解决方案。从数据隐私的角度认识到大数据技术带来的对人类自由意志的侵犯，并保证对主体未来行为的预测结果不作为主体的数据隐私进行披露，就可以在很大程度上避免这种侵犯，甚至成为主体行为规划的一种辅助决策工具。从数据隐私的角度认识人工智能的相关伦理问题，剥夺人工智能相关伦理问题，从数据隐私的角度认识人工智能的数据隐私，使其在信息层面与人类形成不对等，其思想和行为趋于透明，可以很大程度上避免对人类利益的侵害，巩固人类作为控制主体的相对地位。虚拟世界主体的行为道德不受现实世界伦理规范的约束和评判，相关的伦理问题也就随之消解。把数据隐私作为理解人工智能问题的基本出发点，可以帮助我们直接抓住问题的 "症结"，为理解和解决相关伦理问题提供清晰的思路和指导。

　　就伦理规范内化为技术而言，由于数据隐私是通过技术手段数据化的隐私，其相关的伦理问题也是在技术过程中产生的，伦理规范内化为技术显然可以对其作出更精确、更有效的回应和解决。从技术方案的内在矛盾性和自我反思性治理来看，数据隐私本身既是保护对象，又是隐私保护的有效资源。从技术方案的内在矛盾和自我反思性治理来看，数据隐私既是受保护的对象，也是隐私保护的有效资源，当它被用于隐私保护时，会产生新的隐私泄露风险，因此，我们可以将数据隐私划分为不同的隐私等级，评估不同情况下的数据隐私泄露风险，进而在准确把握数据隐私的基础上，处理好人工智能和大数据新伦理问题的技术方案的内在矛盾和自我反思性治理。

总结:
与传统的伦理问题不同，人工智能和大数据伦理问题具有明显的隐蔽性和不可控性，人们在使用计算机新技术的过程中，往往不知道自己的利益受到了侵害或侵害了他人的利益。因此，"美德即知识 "变得尤为重要，人们很难知道什么样的行为是符合道德的：这需要相关主体具备一定的计算机技术专业知识才能做出判断。最好的解决办法是将道德规则内化到计算机系统中，这样道德行为就由技术来执行，人们不再需要自己对有关行为的道德性做出判断。因此，道德对于将道德规范以算法的形式内化到计算机系统中是有价值的，而不道德就是阻碍或破坏这种道德规范内化到技术中。对于既没有这种道德行为能力，也没有这种不道德行为能力的普通人来说，在面对新的计算机技术的道德问题时，他们唯一可以遵循的道德就是站出来维护正义。而这也是我们应该遵循的道德和给出的引领。
